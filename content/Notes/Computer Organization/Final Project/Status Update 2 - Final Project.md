---
id: Status Update 2 - Final Project
aliases: []
tags: []
---

# Final Project Status Update

> [!abstract] Student Information
> Ewan Pedersen
> CS2210
> 10 • 11 • 2024

---

## 1. Summary Of Progress

Up until this second update, I have been focusing on laying the foundations for the project. By now, I know exactly what hardware I am going to need, how the project is going to be structured, and what tasks I need to prioritize first. As of this point, most of my work has been software focussed, and honing my tech stack to run on the more limited hardware of the raspberry pi.

---

## 2. Time Log

| date       | Name | Role                | Description                                                | Time(Hrs) |
| ---------- | ---- | ------------------- | ---------------------------------------------------------- | --------- |
| 10/01/2024 | Ewan | Lead Model Engineer | Purchased full list of parts for project                   | 2         |
| 10/04/2024 | Ewan | Lead Model Engineer | Started collecting labeled TARS voicelogs for LLM training | 2         |
| 10/9/2024  | Ewan | Lead Model Engineer | Began training VOICE generation AI model using Cocqui      | 4         |

---

## 3. Next Steps

As I said in the summary, it has been mostly software up until this point. Going forward, I want to get my physical choice out of the way, and get a solid chassis design ready, so I can go back to focussing on the models that require my attention. Once the parts I have ordered arrived, I can experiment and debug the different parts separately until they all work through manual tests. After that, I can be sure that the hardware is functioning and focus on improving model performance gradually.

---

## 4. Challenges

Data collection has been a lot harder than I thought. Despite his fame in the fan base, there wasn't that much dialogue in the movie Inters taller for TARS, so I have been having to generate some extra textual dialogue for fine tuning the language model. 

This doesn't work for the speech synthesis model, however, as I need actual audio recordings to train it. Luckily, the speech models require much less sample material to get to a functioning prototype.